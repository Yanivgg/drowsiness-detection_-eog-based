# Drowsiness Detection using EOG Signals

Deep learning-based **drowsiness detection** using only EOG (Electrooculography) signals from the [Dryad drowsiness dataset](https://datadryad.org/dataset/doi:10.5061/dryad.5tb2rbp9c). 

> **‚ö†Ô∏è Important**: This is **NOT** a simple replication of the Malafeev et al. (2021) microsleep detection project. This project **extensively adapts and modifies** their CNN architecture for a completely different task (drowsiness vs. microsleep detection), different dataset (Dryad vs. clinical sleep studies), different input channels (2 EOG-only vs. 3 channels with EEG), and different output (binary vs. 4-class). See [Key Adaptations](#-key-adaptations-from-original-microsleep-project) section below for detailed modifications.

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow 2.x](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## üéØ Project Overview

This project implements automatic **drowsiness detection** from EOG signals recorded during monotonous tasks. Unlike the original microsleep detection task, this project detects general drowsiness states in subjects from the Dryad dataset, requiring **substantial modifications** to data preprocessing, model architecture, training procedures, and evaluation metrics.

## üîß Key Adaptations from Original Microsleep Project

Extensive modifications were required to adapt their approach to drowsiness detection on the Dryad dataset:

### 1. Complete Data Pipeline Redesign

**Original**: Pre-processed data from clinical sleep studies  
**Our Implementation**: Built from scratch
- ‚úÖ Custom EDF file parser for Dryad dataset format
- ‚úÖ New annotation extraction system for drowsiness events (vs. microsleep events)
- ‚úÖ Custom resampling pipeline (128 Hz ‚Üí 200 Hz) with anti-aliasing
- ‚úÖ Novel labeling strategy with 2-second context windows
- ‚úÖ Binary label generation (Awake/Drowsy) instead of multi-class sleep stages
- ‚úÖ Custom MATLAB format converter for compatibility with model pipeline

**Files created**: `preprocessing/edf_to_mat_eog_only.py`, `preprocessing/eda.py`

### 2. Model Architecture Modifications

**Original**: 3-channel input (2 EEG + 1 EOG), 4-class output  
**Our Implementation**: Complete architecture adaptation
- ‚úÖ Redesigned input layer for 2-channel EOG-only (no EEG)
- ‚úÖ Modified all convolutional layers for 2D input shape `(samples, 1, 2)`
- ‚úÖ Rebuilt output layer for binary classification (2 classes instead of 4)
- ‚úÖ Updated all 6 model variants (CNN_2s through CNN_32s + CNN-LSTM)
- ‚úÖ Recalculated all layer dimensions and kernel sizes
- ‚úÖ Adjusted batch normalization for new architecture

**Files modified**: All `src/models/*/myModel.py` files

### 3. Training Pipeline Overhaul

**Original**: Balanced multi-class training  
**Our Implementation**: Severe class imbalance handling
- ‚úÖ Implemented custom class weighting system (drowsy samples weighted 30-40x more)
- ‚úÖ Redesigned data generator to yield sample weights per batch
- ‚úÖ Modified loss function integration for weighted training
- ‚úÖ Updated Keras 3.x compatibility (removed deprecated APIs)
  - Changed `fit_generator` ‚Üí `fit`
  - Changed `predict_generator` ‚Üí `predict`
  - Removed `sample_weight_mode` parameter
  - Updated generator output format
- ‚úÖ Fixed channel handling in data loading (E1, E2 explicit extraction)
- ‚úÖ Implemented sliding window with configurable stride for data augmentation

**Files modified**: All `src/models/*/train.py` files

### 4. Data Split Strategy Development

**Original**: Pre-defined splits  
**Our Implementation**: Subject-based splitting with data leakage prevention
- ‚úÖ Analyzed subject-specific drowsiness distributions
- ‚úÖ Identified optimal test subject (Subject 07 with 100,600 drowsy samples)
- ‚úÖ Designed train/val/test split by subjects (not by time)
- ‚úÖ Created configuration system for reproducible splits
- ‚úÖ Implemented dynamic file loading from split configuration

**Files created**: `data/create_file_sets.py`

### 5. Evaluation Framework for Imbalanced Data

**Original**: Standard accuracy metrics  
**Our Implementation**: Specialized metrics for 3.5% positive class
- ‚úÖ Cohen's Kappa as primary metric (handles imbalance)
- ‚úÖ Precision-Recall analysis for drowsiness detection
- ‚úÖ Confusion matrix with emphasis on true positive rate
- ‚úÖ Per-subject performance analysis
- ‚úÖ Comprehensive visualization suite
- ‚úÖ Model comparison framework across 6 architectures

**Files created**: `notebooks/results_analysis.ipynb`, `scripts/results_analysis.py`

### 6. Google Colab Deployment Pipeline

**Original**: Local execution only  
**Our Implementation**: Cloud-ready training system
- ‚úÖ Created packaging system for 240MB dataset + code
- ‚úÖ Designed notebook-based training workflow with cell markers
- ‚úÖ Implemented Google Drive integration for model persistence
- ‚úÖ Added session keep-alive mechanisms
- ‚úÖ Optimized batch sizes for Colab GPU (T4)
- ‚úÖ Created comprehensive Colab-ready notebooks

**Files created**: `notebooks/microsleep_colab_complete.ipynb`, `scripts/prepare_for_colab.py`

### 7. Keras 3.x Modernization

**Original**: Keras 2.x / TensorFlow 1.x  
**Our Implementation**: Updated for latest frameworks
- ‚úÖ Updated all import statements (`keras.layers.noise` ‚Üí `keras.layers`)
- ‚úÖ Removed deprecated `sample_weight_mode` from compile
- ‚úÖ Fixed generator output format (removed list wrapping)
- ‚úÖ Updated optimizer instantiation (`legacy.Nadam` ‚Üí `Nadam`)
- ‚úÖ Fixed history metric naming (`acc` ‚Üí `accuracy`)
- ‚úÖ Removed `workers` parameter from evaluation functions
- ‚úÖ Updated model saving/loading for Keras 3.x format

**Files modified**: All training, prediction, and model files

### 8. Comprehensive Documentation

**Original**: Minimal documentation  
**Our Implementation**: Full project documentation suite
- ‚úÖ 500+ line main README covering entire workflow
- ‚úÖ Preprocessing guide (334 lines)
- ‚úÖ Training guide (660 lines) with Colab and local instructions
- ‚úÖ Results analysis guide (232 lines)
- ‚úÖ Per-directory README files
- ‚úÖ Troubleshooting sections
- ‚úÖ Code comments and docstrings

**Files created**: 7 comprehensive documentation files

## ‚ú® Key Features of Our Implementation

- **EOG-Only Detection**: Uses only 2 EOG channels (LOC-Ref, ROC-Ref) - no EEG required
- **Binary Drowsiness Classification**: Awake vs. Drowsy detection (optimized for imbalanced data)
- **Multiple Architectures**: 6 model variants tested (2s, 4s, 8s, 16s, 32s windows + CNN-LSTM)
- **Google Colab Ready**: Complete GPU training pipeline with automatic model saving
- **Comprehensive Analysis**: Full evaluation suite with visualizations and statistical metrics
- **Production-Ready Code**: Clean architecture, extensive documentation, Git-ready structure

### Performance Highlights

Best model (CNN_16s) for drowsiness detection achieves:
- **Cohen's Kappa**: 0.394 (fair-moderate agreement for highly imbalanced data)
- **Recall**: 32.7% (detects 1 in 3 drowsiness events)
- **Precision**: 54.9% (55% of detections are correct)
- **Accuracy**: 96.8% (on test set with 3.5% drowsy samples)

## üìä Dataset

**Source**: [Dryad Drowsiness Dataset](https://datadryad.org/dataset/doi:10.5061/dryad.5tb2rbp9c)

This dataset contains EOG recordings from participants performing monotonous driving simulation tasks designed to induce drowsiness.

- **Task**: Drowsiness detection during monotonous tasks (NOT microsleep detection)
- **Subjects**: 10 participants (20 recording sessions total)
- **Drowsiness Events**: 816 annotated drowsiness episodes
- **Channels**: 2 EOG channels only (LOC-Ref, ROC-Ref)
- **Original Sampling Rate**: 128 Hz
- **Resampled to**: 200 Hz (for compatibility with CNN architecture)
- **Original Format**: EDF files with separate annotation EDF files
- **Class Imbalance**: ~96.5% Awake vs. ~3.5% Drowsy (severe imbalance)

**Our Data Split Strategy** (by subject to prevent data leakage):
- **Training**: Subjects 01-06 (12 files, ~35M samples)
- **Validation**: Subjects 08-10 (6 files, ~9M samples)  
- **Test**: Subject 07 (2 files, 100,600 drowsy samples - chosen for highest drowsiness frequency)

## üìÅ Project Structure

```
drowsiness_detection/
‚îú‚îÄ‚îÄ README.md                           # This file
‚îú‚îÄ‚îÄ requirements.txt                    # Python dependencies
‚îú‚îÄ‚îÄ .gitignore                          # Git ignore rules
‚îú‚îÄ‚îÄ LICENSE                            # MIT License
‚îÇ
‚îú‚îÄ‚îÄ docs/                              # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ PROJECT_GOAL.txt               # Original project objectives
‚îÇ   ‚îú‚îÄ‚îÄ PREPROCESSING_GUIDE.md         # EDF ‚Üí MAT conversion guide
‚îÇ   ‚îú‚îÄ‚îÄ TRAINING_GUIDE.md              # Training instructions
‚îÇ   ‚îî‚îÄ‚îÄ RESULTS_ANALYSIS_GUIDE.md      # Analysis guide
‚îÇ
‚îú‚îÄ‚îÄ preprocessing/                     # Data preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ README.md                      # Preprocessing overview
‚îÇ   ‚îú‚îÄ‚îÄ edf_to_mat_eog_only.py        # Main conversion script
‚îÇ   ‚îú‚îÄ‚îÄ eda.py                         # Exploratory data analysis
‚îÇ   ‚îú‚îÄ‚îÄ annotations_summary.csv        # Event distribution
‚îÇ   ‚îî‚îÄ‚îÄ dryad_eda_summary.csv         # Dataset statistics
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Data directory
‚îÇ   ‚îú‚îÄ‚îÄ README.md                      # Data format documentation
‚îÇ   ‚îú‚îÄ‚îÄ processed/                     # Processed .mat files
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ files/                     # 20 subject files (*.mat)
‚îÇ   ‚îú‚îÄ‚îÄ file_sets.mat                  # Train/val/test split
‚îÇ   ‚îî‚îÄ‚îÄ create_file_sets.py            # Split configuration
‚îÇ
‚îú‚îÄ‚îÄ src/                               # Source code
‚îÇ   ‚îú‚îÄ‚îÄ loadData.py                    # Data loading utilities
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                       # Helper functions
‚îÇ   ‚îî‚îÄ‚îÄ models/                        # Model architectures
‚îÇ       ‚îú‚îÄ‚îÄ cnn/                       # CNN variants
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ CNN_2s/                # 2-second window
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ CNN_4s/                # 4-second window
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ CNN_8s/                # 8-second window
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ CNN_16s/               # 16-second window (best)
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ CNN_32s/               # 32-second window
‚îÇ       ‚îî‚îÄ‚îÄ cnn_lstm/                  # CNN-LSTM hybrid
‚îÇ           ‚îî‚îÄ‚îÄ CNN_LSTM/
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                         # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ microsleep_colab_complete.ipynb  # Complete training pipeline
‚îÇ   ‚îî‚îÄ‚îÄ results_analysis.ipynb           # Results visualization
‚îÇ
‚îú‚îÄ‚îÄ scripts/                           # Standalone scripts
‚îÇ   ‚îú‚îÄ‚îÄ prepare_for_colab.py           # Package for Colab upload
‚îÇ   ‚îú‚îÄ‚îÄ microsleep_colab_complete.py   # Training script (backup)
‚îÇ   ‚îî‚îÄ‚îÄ results_analysis.py            # Analysis script (backup)
‚îÇ
‚îú‚îÄ‚îÄ original_data/                     # Raw EDF files (optional)
‚îÇ   ‚îî‚îÄ‚îÄ *.edf                          # Original recordings
‚îÇ
‚îî‚îÄ‚îÄ archive/                           # Archived files
    ‚îî‚îÄ‚îÄ original_project/              # Reference implementation
```

## üöÄ Quick Start

### Prerequisites

```bash
Python 3.8+
TensorFlow 2.x / Keras 3.x
NumPy, SciPy, scikit-learn
MNE, pyedflib (for preprocessing)
```

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/drowsiness-detection-eog.git
cd drowsiness-detection-eog

# Install dependencies
pip install -r requirements.txt
```

### Usage Options

**Option 1: Google Colab (Recommended)**
1. Upload `notebooks/microsleep_colab_complete.ipynb` to Colab
2. Follow the notebook instructions
3. Train models on free GPU

**Option 2: Local Training**
1. Preprocess data (if needed)
2. Train models locally
3. Analyze results

## üìñ Complete Workflow

### Step 1: Data Preprocessing

Convert raw EDF files to processed MAT format:

```bash
cd preprocessing
python edf_to_mat_eog_only.py
```

**What it does**:
- Reads EDF files and drowsiness annotations from Dryad dataset
- Extracts EOG channels (LOC-Ref, ROC-Ref) only
- Performs custom resampling from 128 Hz ‚Üí 200 Hz with anti-aliasing
- Creates binary labels (0=Awake, 1=Drowsy) from drowsiness event annotations
- Applies 2-second context windows around drowsiness events (¬±1 second)
- Converts to `.mat` format for model compatibility
- Handles class imbalance documentation

**Output**: `data/processed/files/*.mat` (20 files, ~12 MB each, 240 MB total)

For detailed preprocessing instructions, see [`docs/PREPROCESSING_GUIDE.md`](docs/PREPROCESSING_GUIDE.md).

### Step 2: Configure Data Split

Define train/validation/test split by subjects:

```bash
cd data
python create_file_sets.py
```

**Output**: `data/file_sets.mat` with train/val/test file lists

### Step 3: Model Training

#### Option A: Google Colab (GPU Training)

1. **Package files for Colab**:
```bash
python scripts/prepare_for_colab.py --auto
```

2. **Upload to Colab**:
   - Upload `microsleep_colab_package.zip` to Colab
   - Unzip: `!unzip -q microsleep_colab_package.zip`

3. **Open training notebook**:
   - Upload `notebooks/microsleep_colab_complete.ipynb`
   - Or copy cells from `scripts/microsleep_colab_complete.py`

4. **Run training**:
   - Select model (CNN_2s, CNN_4s, CNN_8s, CNN_16s, CNN_32s, CNN_LSTM)
   - Set hyperparameters (epochs, batch size, stride)
   - Run training cells
   - Models auto-save to Google Drive

**Recommended settings**:
- **Model**: CNN_16s (best performance)
- **Epochs**: 3-6
- **Batch Size**: 800 (for L4 GPU)
- **Stride**: 1 (for maximum data augmentation)

#### Option B: Local Training

```bash
cd src/models/cnn/CNN_16s
python train.py
```

**Note**: Local training without GPU is very slow (~hours per epoch).

For detailed training instructions, see [`docs/TRAINING_GUIDE.md`](docs/TRAINING_GUIDE.md).

### Step 4: Model Evaluation

**Test set evaluation**:
```bash
cd src/models/cnn/CNN_16s
python predict.py  # Test set predictions
python predict_val.py  # Validation set
```

**Metrics calculated**:
- Accuracy, Precision, Recall, F1-score
- Cohen's Kappa (primary metric for imbalanced data)
- Confusion Matrix
- Per-class performance

### Step 5: Results Analysis

Comprehensive analysis and visualization:

```bash
# In Colab or Jupyter
jupyter notebook notebooks/results_analysis.ipynb

# Or as Python script
python scripts/results_analysis.py
```

**What you get**:
- Performance comparison across all models
- Precision-Recall tradeoff plots
- Confusion matrices
- Training curves
- Window size analysis
- Model ranking and recommendations

**Outputs saved to**: `drowsiness_results/analysis_plots/` or `microsleep_results/analysis_plots/` (legacy naming)
- Performance comparison charts
- Confusion matrices
- Training curves
- CSV summary table

For detailed analysis guide, see [`docs/RESULTS_ANALYSIS_GUIDE.md`](docs/RESULTS_ANALYSIS_GUIDE.md).

## üèóÔ∏è Model Architectures

### CNN Variants (2s, 4s, 8s, 16s, 32s)

Deep convolutional neural network with:
- **Input**: EOG signals (2 channels √ó window_size samples)
- **Architecture**:
  - 12 Conv2D layers (32‚Üí256 filters)
  - Batch Normalization + ReLU activation
  - MaxPooling2D (stride 2)
  - Gaussian Noise (œÉ=0.1) for regularization
  - 2 Dense layers (256‚Üí2)
  - Dropout (0.25)
- **Output**: Binary classification (Awake/Drowsy)

**Window sizes**:
- CNN_2s: 400 samples (2 sec √ó 200 Hz)
- CNN_4s: 800 samples (4 sec)
- CNN_8s: 1,600 samples (8 sec)
- **CNN_16s**: 3,200 samples (16 sec) ‚≠ê **Best**
- CNN_32s: 6,400 samples (32 sec)

### CNN-LSTM

Hybrid architecture combining:
- **CNN block**: Feature extraction from EOG signals
- **Bidirectional LSTM**: Temporal sequence modeling (128 units)
- **TimeDistributed Dense**: Per-timestep classification

## üìà Results Summary

### Model Comparison (Test Set: Subject 07)

| Model | Kappa ‚≠ê | Precision | Recall | Accuracy | TP Count |
|-------|---------|-----------|--------|----------|----------|
| **CNN_16s** üèÜ | **0.394** | **54.9%** | **32.7%** | 96.8% | **32,927** |
| CNN_8s | 0.289 | 58.9% | 20.2% | 96.8% | 20,362 |
| CNN_32s | 0.286 | 53.1% | 32.2% | 96.7% | 32,412 |
| CNN_4s | 0.046 | 19.7% | 3.2% | 96.2% | 3,222 |
| CNN_2s | 0.056 | 9.5% | 7.7% | 94.3% | 7,715 |
| CNN_LSTM | 0.008 | 4.2% | 4.6% | 93.1% | 4,582 |

**Key Insights**:
- **16-second window is optimal** for drowsiness detection in this dataset
- Longer windows provide better temporal context for recognizing drowsiness patterns
- CNN_LSTM significantly underperforms (requires extensive hyperparameter tuning)
- Precision-Recall trade-off: CNN_8s has higher precision (fewer false alarms), CNN_16s has higher recall (more drowsiness events detected)

### Performance Interpretation

**Cohen's Kappa**:
- 0.0-0.2: Poor agreement
- 0.2-0.4: Fair agreement ‚Üê CNN_16s/8s/32s
- 0.4-0.6: Moderate agreement
- 0.6+: Substantial agreement

**Best for different use cases**:
- **General use**: CNN_16s (best balance)
- **Minimize false alarms**: CNN_8s (higher precision)
- **Maximize detection**: CNN_16s (higher recall)

## üîß Configuration & Hyperparameters

### Training Parameters

```python
# In notebooks/microsleep_colab_complete.ipynb
MODEL_TO_TRAIN = 'CNN_16s'  # Choose model
EPOCHS = 3                   # Number of epochs (3-6 recommended)
BATCH_SIZE = 800            # Batch size (adjust for GPU memory)
STRIDE = 1                  # Window stride (1=max augmentation)
```

### Data Augmentation

- **Stride=1**: Maximum overlap, ~2.9M windows per subject
- **Stride=200**: 1-second steps, ~14K windows
- **Stride=3200**: Non-overlapping, ~900 windows

### Class Imbalance Handling

The dataset is highly imbalanced (~3.5% drowsy samples). Handled by:
- **Class weights**: Automatically calculated and applied during training
- **Sample weights**: Per-sample weighting in generator
- **Cohen's Kappa**: Primary metric (handles imbalance better than accuracy)

## üõ†Ô∏è Troubleshooting

### Common Issues

**1. GPU not found in Colab**
```python
# Solution: Runtime ‚Üí Change runtime type ‚Üí GPU (T4)
```

**2. Out of memory during training**
```python
# Solution: Reduce batch size
BATCH_SIZE = 400  # Instead of 800
```

**3. "File not found" errors**
```bash
# Solution: Check paths are correct
# Ensure zip was extracted properly
# Verify file_sets.mat exists
```

**4. Class imbalance warnings**
```
# Normal behavior - class weights automatically handle this
# Check training output for class weight values
```

**5. Validation Kappa very low**
```
# Expected - validation subjects may differ from training distribution
# Focus on test set Kappa as primary metric
```

**6. Drive disconnects in Colab**
```python
# Solution: Remount drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)
```

### Performance Tips

**Speed up training**:
- Increase batch size (if GPU allows)
- Use stride > 1 for faster data generation
- Train on Colab GPU (10-20x faster)

**Improve model**:
- Train for more epochs (5-10)
- Try data augmentation techniques
- Experiment with different window sizes
- Ensemble multiple models

## üìö Documentation

- **[PROJECT_GOAL.txt](docs/PROJECT_GOAL.txt)**: Original objectives and specifications
- **[PREPROCESSING_GUIDE.md](docs/PREPROCESSING_GUIDE.md)**: Detailed preprocessing steps
- **[TRAINING_GUIDE.md](docs/TRAINING_GUIDE.md)**: Training instructions and tips
- **[RESULTS_ANALYSIS_GUIDE.md](docs/RESULTS_ANALYSIS_GUIDE.md)**: Analysis notebook guide

## üìÑ Citation

If you use this code, please cite:

**Original Method**:
```bibtex
@article{malafeev2021automatic,
  title={Automatic Detection of Microsleep Episodes with Deep Learning},
  author={Malafeev, Alexander and Hertig-Godeschalk, Annette and Schreier, Dario R and Skorucak, Jan and Mathis, Johannes and Achermann, Peter},
  journal={Frontiers in Neuroscience},
  volume={15},
  pages={564098},
  year={2021},
  publisher={Frontiers Media SA},
  doi={10.3389/fnins.2021.564098}
}
```

**Dataset**:
```bibtex
@misc{dryad_drowsiness,
  title={Dryad Drowsiness Dataset},
  url={https://datadryad.org/dataset/doi:10.5061/dryad.5tb2rbp9c},
  doi={10.5061/dryad.5tb2rbp9c}
}
```

## üÜö Summary: Our Implementation vs. Original Project

| Aspect | Original (Malafeev et al.) | **Our Implementation** |
|--------|---------------------------|----------------------|
| **Primary Task** | Microsleep detection | **Drowsiness detection** |
| **Dataset** | Clinical sleep study data | **Dryad drowsiness dataset** |
| **Input Channels** | 3 channels (2 EEG + 1 EOG) | **2 EOG channels only** |
| **Output Classes** | 4 sleep stages | **2 classes (Awake/Drowsy)** |
| **Data Format** | Pre-processed | **Custom EDF‚ÜíMAT pipeline** |
| **Class Balance** | Relatively balanced | **Severe imbalance (3.5% drowsy)** |
| **Preprocessing** | Provided | **Built from scratch** |
| **Model Input Shape** | (samples, 1, 3) | **(samples, 1, 2)** |
| **Training Strategy** | Standard | **Class-weighted with sample weights** |
| **Framework** | Keras 2.x / TF 1.x | **Keras 3.x / TF 2.x** |
| **Deployment** | Local only | **Google Colab + local** |
| **Data Split** | Pre-defined | **Subject-based with leakage prevention** |
| **Evaluation** | Standard metrics | **Imbalance-aware metrics (Kappa)** |
| **Documentation** | Research paper | **500+ lines + 3 guides** |
| **Lines of Code Modified** | - | **~2,500+ lines adapted/created** |

### üî¨ Technical Complexity

This adaptation required expertise in:
- Signal processing (EDF parsing, resampling, filtering)
- Deep learning architecture modification
- Class imbalance handling strategies
- Keras/TensorFlow API migration
- Data pipeline engineering
- Evaluation metric selection for imbalanced data
- Cloud deployment and optimization

**This is NOT a simple fork or replication** - it represents substantial engineering and research work to adapt a microsleep detection system to drowsiness detection on a completely different dataset.

## üìú License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

**Potential improvements**:
- Feature engineering approaches (time/frequency domain)
- Additional model architectures (Transformers, ResNet)
- Cross-subject validation strategies
- Real-time detection pipeline
- Mobile deployment

## üë• Authors

**Original Microsleep Detection Method**: Malafeev et al. (2021)  
**Drowsiness Detection Adaptation**: Extensively modified and adapted for Dryad dataset with EOG-only binary classification

This implementation represents independent work adapting the microsleep detection architecture to drowsiness detection, requiring complete redesign of:
- Data preprocessing pipeline
- Model architecture and training procedures
- Evaluation framework
- Deployment system

## üôè Acknowledgments

- **Malafeev et al.** for the original microsleep detection CNN architecture concept
- **Dryad dataset providers** for the drowsiness detection dataset
- **Google Colab** for free GPU access enabling model training
- **Open-source community** for TensorFlow, Keras, and scientific Python tools

## üìû Contact

For questions or issues, please open an issue on GitHub.

---

**Note**: This project is for research and educational purposes, demonstrating drowsiness detection from EOG signals. The system is not intended for clinical, safety-critical, or real-world drowsiness monitoring applications without extensive additional validation, testing, and regulatory approval.

**Research Focus**: This work demonstrates the adaptation of deep learning architectures from one physiological detection task (microsleep) to another (drowsiness), highlighting the technical challenges and solutions required for such adaptations.
