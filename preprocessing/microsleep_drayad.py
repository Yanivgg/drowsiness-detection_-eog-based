# -*- coding: utf-8 -*-
"""microsleep_drayad.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k5fiDg_CsKYmXGBnDZgAtLFafAdKR3N9
"""

!pip install numpy scipy tensorflow keras scikit-learn mne pyedflib tqdm

from google.colab import drive
drive.mount('/content/drive')

import os
import scipy.io as spio

data_dir = "/content/drive/MyDrive/microsleep_drayad"

files = [f for f in os.listdir(data_dir) if f.endswith('.mat')]
print("Found", len(files), "files")

example = spio.loadmat(os.path.join(data_dir, files[0]), struct_as_record=False, squeeze_me=True)
data = example['Data']
print("Fields inside Data:")
print(dir(data))

# ==========================================
# loadData_colab.py  (faithful to original project)
# ==========================================

import scipy.io as spio
import numpy as np
import os
from tqdm import tqdm

def load_recording(mat_path):
    """Load a single .mat file and return E1, E2, labels."""
    mat = spio.loadmat(mat_path, struct_as_record=False, squeeze_me=True)
    D = mat['Data']
    E1 = D.E1
    E2 = D.E2
    labels = D.labels_O1.astype(int)
    return E1, E2, labels


def create_windows(E1, E2, labels, fs=200, window_sec=16, stride_sec=2):
    """
    Create overlapping windows (E1, E2, label) using Contain labeling.
    Label = 1 if any sample in the window has label=1.
    """
    w_len = int(window_sec * fs)
    stride = int(stride_sec * fs)

    X, y = [], []
    n_samples = len(E1)

    for start in range(0, n_samples - w_len, stride):
        end = start + w_len
        label_window = 1 if np.any(labels[start:end]) else 0
        win_e1 = E1[start:end]
        win_e2 = E2[start:end]
        X.append(np.stack([win_e1, win_e2], axis=-1))  # shape: (samples, 2)
        y.append(label_window)

    X = np.array(X)
    y = np.array(y)
    return X, y


def normalize_original(X):
    """
    Normalize exactly like the original project:
    divide by 100, then clip to [-1, 1].
    """
    X = X / 100.0
    X = np.clip(X, -1.0, 1.0)
    return X


def load_dataset(data_dir, fs=200, window_sec=16, stride_sec=2,
                 val_ratio=0.15, test_ratio=0.15):
    """
    Load all .mat recordings from a directory.
    Split by files (not randomly by windows) to avoid temporal data leakage.
    """
    files = sorted([f for f in os.listdir(data_dir) if f.endswith('.mat')])
    n_total = len(files)
    assert n_total > 3, "Need at least 3 files to split safely."

    n_test = int(n_total * test_ratio)
    n_val = int(n_total * val_ratio)
    n_train = n_total - n_val - n_test

    files_train = files[:n_train]
    files_val   = files[n_train:n_train + n_val]
    files_test  = files[n_train + n_val:]

    print(f"Total files: {n_total}")
    print(f"→ Train: {len(files_train)}, Val: {len(files_val)}, Test: {len(files_test)}")

    def load_split(file_list, split_name):
        X_list, y_list = [], []
        for f in tqdm(file_list, desc=f"Loading {split_name}"):
            path = os.path.join(data_dir, f)
            E1, E2, labels = load_recording(path)
            X, y = create_windows(E1, E2, labels, fs, window_sec, stride_sec)
            X_list.append(X)
            y_list.append(y)
        X = np.concatenate(X_list, axis=0)
        y = np.concatenate(y_list, axis=0)
        X = normalize_original(X)
        print(f"{split_name}: {len(X)} windows ({np.mean(y)*100:.2f}% positive)")
        return X, y

    X_train, y_train = load_split(files_train, "Train")
    X_val, y_val = load_split(files_val, "Validation")
    X_test, y_test = load_split(files_test, "Test")

    print("✅ Dataset loaded successfully (original normalization).")
    return (X_train, y_train), (X_val, y_val), (X_test, y_test)

data_dir = "/content/drive/MyDrive/microsleep_drayad"
(train_X, train_y), (val_X, val_y), (test_X, test_y) = load_dataset(data_dir)

